- name: Set varialbles
  ansible.builtin.set_fact:
    rpfx: "{{ resource_group | hash('md5') | truncate(8, True, '') }}"
    noderpfx: "{{ resource_group | hash('md5') | truncate(4, True, '') }}"

- name: Include aks tasks
  ansible.builtin.include_tasks: minimal-cluster.yml

- name: Find available k8s version
  azure_rm_aksversion_info:
    location: eastus
  register: versions

- name: Create an AKS instance (check mode)
  azure_rm_aks:
    name: "aks{{ rpfx }}"
    resource_group: "{{ resource_group }}"
    location: eastus
    dns_prefix: "aks{{ rpfx }}"
    kubernetes_version: "{{ versions.azure_aks_versions[0] }}"
    service_principal:
      client_id: "{{ azure_client_id }}"
      client_secret: "{{ azure_secret }}"
    linux_profile:
      admin_username: azureuser
      ssh_key: ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDSPmiqkvDH1/+MDAVDZT8381aYqp73Odz8cnD5hegNhqtXajqtiH0umVg7HybX3wt1HjcrwKJovZURcIbbcDvzdH2bnYbF93T4OLXA0bIfuIp6M86x1iutFtXdpN3TTicINrmSXEE2Ydm51iMu77B08ZERjVaToya2F7vC+egfoPvibf7OLxE336a5tPCywavvNihQjL8sjgpDT5AAScjb3YqK/6VLeQ18Ggt8/ufINsYkb+9/Ji/3OcGFeflnDXq80vPUyF3u4iIylob6RSZenC38cXmQB05tRNxS1B6BXCjMRdy0v4pa7oKM2GA4ADKpNrr0RI9ed+peRFwmsclH test@ansible
    agent_pool_profiles:
      - name: default
        count: 1
        vm_size: Standard_B2s
        type: VirtualMachineScaleSets
        mode: System
        node_labels: {"release":"stable"}
        max_pods: 42
        availability_zones:
          - 1
          - 2
    node_resource_group: "node{{ noderpfx }}"
    enable_rbac: true
    network_profile:
      load_balancer_sku: standard
  check_mode: true

- name: Check there is no AKS created
  azure_rm_aks_info:
    name: "aks{{ rpfx }}"
    resource_group: "{{ resource_group }}"
  register: fact

- name: Check there is no AKS created
  ansible.builtin.assert:
    that:
      - "fact.aks | length == 0"

- name: Create an AKS instance
  azure_rm_aks:
    name: "aks{{ rpfx }}"
    resource_group: "{{ resource_group }}"
    location: eastus
    dns_prefix: "aks{{ rpfx }}"
    kubernetes_version: "{{ versions.azure_aks_versions[0] }}"
    service_principal:
      client_id: "{{ azure_client_id }}"
      client_secret: "{{ azure_secret }}"
    linux_profile:
      admin_username: azureuser
      ssh_key: ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDSPmiqkvDH1/+MDAVDZT8381aYqp73Odz8cnD5hegNhqtXajqtiH0umVg7HybX3wt1HjcrwKJovZURcIbbcDvzdH2bnYbF93T4OLXA0bIfuIp6M86x1iutFtXdpN3TTicINrmSXEE2Ydm51iMu77B08ZERjVaToya2F7vC+egfoPvibf7OLxE336a5tPCywavvNihQjL8sjgpDT5AAScjb3YqK/6VLeQ18Ggt8/ufINsYkb+9/Ji/3OcGFeflnDXq80vPUyF3u4iIylob6RSZenC38cXmQB05tRNxS1B6BXCjMRdy0v4pa7oKM2GA4ADKpNrr0RI9ed+peRFwmsclH test@ansible
    agent_pool_profiles:
      - name: default
        count: 1
        vm_size: Standard_B2s
        type: VirtualMachineScaleSets
        mode: System
        node_labels: {"release":"stable"}
        max_pods: 42
        availability_zones:
          - 1
          - 2
    node_resource_group: "node{{ noderpfx }}"
    enable_rbac: true
    network_profile:
      load_balancer_sku: standard
  register: output

- name: Assert the AKS instance is well created
  ansible.builtin.assert:
    that:
      - output.changed
      - output.provisioning_state == 'Succeeded'

- name: Get AKS fact
  azure_rm_aks_info:
    name: "aks{{ rpfx }}"
    resource_group: "{{ resource_group }}"
  register: fact

- name: Assert fact returns the created one
  ansible.builtin.assert:
    that:
      - "fact.aks | length == 1"
      - fact.aks[0].id == output.id
      - fact.aks[0].agent_pool_profiles[0].availability_zones == ["1", "2"]
      - fact.aks[0].agent_pool_profiles[0].mode == "System"
      - fact.aks[0].agent_pool_profiles[0].node_labels | length == 1

- name: Update an AKS instance node_labels
  azure_rm_aks:
    name: "aks{{ rpfx }}"
    resource_group: "{{ resource_group }}"
    location: eastus
    dns_prefix: "aks{{ rpfx }}"
    kubernetes_version: "{{ versions.azure_aks_versions[0] }}"
    service_principal:
      client_id: "{{ azure_client_id }}"
      client_secret: "{{ azure_secret }}"
    linux_profile:
      admin_username: azureuser
      ssh_key: ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDSPmiqkvDH1/+MDAVDZT8381aYqp73Odz8cnD5hegNhqtXajqtiH0umVg7HybX3wt1HjcrwKJovZURcIbbcDvzdH2bnYbF93T4OLXA0bIfuIp6M86x1iutFtXdpN3TTicINrmSXEE2Ydm51iMu77B08ZERjVaToya2F7vC+egfoPvibf7OLxE336a5tPCywavvNihQjL8sjgpDT5AAScjb3YqK/6VLeQ18Ggt8/ufINsYkb+9/Ji/3OcGFeflnDXq80vPUyF3u4iIylob6RSZenC38cXmQB05tRNxS1B6BXCjMRdy0v4pa7oKM2GA4ADKpNrr0RI9ed+peRFwmsclH test@ansible
    agent_pool_profiles:
      - name: default
        count: 1
        vm_size: Standard_B2s
        type: VirtualMachineScaleSets
        mode: System
        node_labels: {"release":"stable", "environment":"dev"}
        max_pods: 42
        availability_zones:
          - 1
          - 2
    node_resource_group: "node{{ noderpfx }}"
    enable_rbac: true
    network_profile:
      load_balancer_sku: standard
  register: output

- name: Assert the AKS instance is well update
  ansible.builtin.assert:
    that:
      - output.changed

- name: Get AKS fact
  azure_rm_aks_info:
    name: "aks{{ rpfx }}"
    resource_group: "{{ resource_group }}"
  register: fact

- name: Assert fact returns the created one
  ansible.builtin.assert:
    that:
      - "fact.aks | length == 1"
      - fact.aks[0].id == output.id
      - fact.aks[0].agent_pool_profiles[0].node_labels | length == 2

- name: Get AKS upgrade versions
  azure_rm_aksupgrade_info:
    name: "aks{{ rpfx }}"
    resource_group: "{{ resource_group }}"
  register: upgrades

- name: Assert available control-plane versions for upgrade
  ansible.builtin.assert:
    that:
      - "upgrades.azure_aks_upgrades.control_plane_profile.kubernetes_version == versions.azure_aks_versions[0]"
      - "upgrades.azure_aks_upgrades.control_plane_profile.upgrades | length > 0"

- name: Create an AKS instance (idempotent)
  azure_rm_aks:
    name: "aks{{ rpfx }}"
    resource_group: "{{ resource_group }}"
    location: eastus
    dns_prefix: "aks{{ rpfx }}"
    kubernetes_version: "{{ versions.azure_aks_versions[0] }}"
    service_principal:
      client_id: "{{ azure_client_id }}"
    linux_profile:
      admin_username: azureuser
      ssh_key: ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDSPmiqkvDH1/+MDAVDZT8381aYqp73Odz8cnD5hegNhqtXajqtiH0umVg7HybX3wt1HjcrwKJovZURcIbbcDvzdH2bnYbF93T4OLXA0bIfuIp6M86x1iutFtXdpN3TTicINrmSXEE2Ydm51iMu77B08ZERjVaToya2F7vC+egfoPvibf7OLxE336a5tPCywavvNihQjL8sjgpDT5AAScjb3YqK/6VLeQ18Ggt8/ufINsYkb+9/Ji/3OcGFeflnDXq80vPUyF3u4iIylob6RSZenC38cXmQB05tRNxS1B6BXCjMRdy0v4pa7oKM2GA4ADKpNrr0RI9ed+peRFwmsclH test@ansible
    agent_pool_profiles:
      - name: default
        count: 1
        vm_size: Standard_B2s
        type: VirtualMachineScaleSets
        mode: System
        max_pods: 42
        availability_zones:
          - 1
          - 2
    node_resource_group: "node{{ noderpfx }}"
    enable_rbac: true
    network_profile:
      load_balancer_sku: standard
  register: output

- name: Assert idempotent
  ansible.builtin.assert:
    that:
      - not output.changed

- name: Get available version
  azure_rm_aksversion_info:
    location: eastus
    version: "{{ versions.azure_aks_versions[0] }}"
  register: version1

- name: Upgrade the AKS instance with addon
  azure_rm_aks:
    name: "aks{{ rpfx }}"
    resource_group: "{{ resource_group }}"
    location: eastus
    dns_prefix: "aks{{ rpfx }}"
    kubernetes_version: "{{ version1.azure_aks_versions[0] }}"
    service_principal:
      client_id: "{{ azure_client_id }}"
    linux_profile:
      admin_username: azureuser
      ssh_key: ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDSPmiqkvDH1/+MDAVDZT8381aYqp73Odz8cnD5hegNhqtXajqtiH0umVg7HybX3wt1HjcrwKJovZURcIbbcDvzdH2bnYbF93T4OLXA0bIfuIp6M86x1iutFtXdpN3TTicINrmSXEE2Ydm51iMu77B08ZERjVaToya2F7vC+egfoPvibf7OLxE336a5tPCywavvNihQjL8sjgpDT5AAScjb3YqK/6VLeQ18Ggt8/ufINsYkb+9/Ji/3OcGFeflnDXq80vPUyF3u4iIylob6RSZenC38cXmQB05tRNxS1B6BXCjMRdy0v4pa7oKM2GA4ADKpNrr0RI9ed+peRFwmsclH test@ansible
    agent_pool_profiles:
      - name: default
        count: 1
        vm_size: Standard_B2s
        type: VirtualMachineScaleSets
        mode: System
        max_pods: 42
        availability_zones:
          - 1
          - 2
    node_resource_group: "node{{ noderpfx }}"
    addon:
      http_application_routing: {}
    network_profile:
      network_plugin: kubenet
      load_balancer_sku: standard
    enable_rbac: true
  register: output

- name: Assert the AKS instance is upgraded
  ansible.builtin.assert:
    that:
      - output.changed
      - output.kubernetes_version == version1.azure_aks_versions[0]
      - output.addon.httpApplicationRouting.enabled ==  True
      - output.agent_pool_profiles[0].count == 1
      - output.network_profile.network_plugin == 'kubenet'

- name: Upgrade the AKS instance with addon (idempontent)
  azure_rm_aks:
    name: "aks{{ rpfx }}"
    resource_group: "{{ resource_group }}"
    location: eastus
    dns_prefix: "aks{{ rpfx }}"
    kubernetes_version: "{{ version1.azure_aks_versions[0] }}"
    service_principal:
      client_id: "{{ azure_client_id }}"
    linux_profile:
      admin_username: azureuser
      ssh_key: ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDSPmiqkvDH1/+MDAVDZT8381aYqp73Odz8cnD5hegNhqtXajqtiH0umVg7HybX3wt1HjcrwKJovZURcIbbcDvzdH2bnYbF93T4OLXA0bIfuIp6M86x1iutFtXdpN3TTicINrmSXEE2Ydm51iMu77B08ZERjVaToya2F7vC+egfoPvibf7OLxE336a5tPCywavvNihQjL8sjgpDT5AAScjb3YqK/6VLeQ18Ggt8/ufINsYkb+9/Ji/3OcGFeflnDXq80vPUyF3u4iIylob6RSZenC38cXmQB05tRNxS1B6BXCjMRdy0v4pa7oKM2GA4ADKpNrr0RI9ed+peRFwmsclH test@ansible
    agent_pool_profiles:
      - name: default
        count: 1
        vm_size: Standard_B2s
        type: VirtualMachineScaleSets
        mode: System
        max_pods: 42
        availability_zones:
          - 1
          - 2
    node_resource_group: "node{{ noderpfx }}"
    addon:
      http_application_routing: {}
    network_profile:
      network_plugin: kubenet
      load_balancer_sku: standard
    enable_rbac: true
  register: output

- name: Assert the aks idempotent
  ansible.builtin.assert:
    that:
      - not output.changed

- name: Upgrade the AKS instance with agent pool profiles
  azure_rm_aks:
    name: "aks{{ rpfx }}"
    resource_group: "{{ resource_group }}"
    location: eastus
    dns_prefix: "aks{{ rpfx }}"
    kubernetes_version: "{{ version1.azure_aks_versions[0] }}"
    service_principal:
      client_id: "{{ azure_client_id }}"
      client_secret: "{{ azure_secret }}"
    linux_profile:
      admin_username: azureuser
      ssh_key: ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDSPmiqkvDH1/+MDAVDZT8381aYqp73Odz8cnD5hegNhqtXajqtiH0umVg7HybX3wt1HjcrwKJovZURcIbbcDvzdH2bnYbF93T4OLXA0bIfuIp6M86x1iutFtXdpN3TTicINrmSXEE2Ydm51iMu77B08ZERjVaToya2F7vC+egfoPvibf7OLxE336a5tPCywavvNihQjL8sjgpDT5AAScjb3YqK/6VLeQ18Ggt8/ufINsYkb+9/Ji/3OcGFeflnDXq80vPUyF3u4iIylob6RSZenC38cXmQB05tRNxS1B6BXCjMRdy0v4pa7oKM2GA4ADKpNrr0RI9ed+peRFwmsclH test@ansible
    agent_pool_profiles:
      - name: default
        count: 1
        vm_size: Standard_B2s
        type: VirtualMachineScaleSets
        mode: System
        enable_auto_scaling: true
        max_count: 6
        min_count: 1
        max_pods: 42
        availability_zones:
          - 1
          - 2
    node_resource_group: "node{{ noderpfx }}"
    enable_rbac: true
    network_profile:
      load_balancer_sku: standard
  register: output
  ignore_errors: true

- name: Assert the AKS instance is well created
  ansible.builtin.assert:
    that:
      - output.changed
      - output.provisioning_state == 'Succeeded'
  ignore_errors: true
  register: ignore_errors_register

- name: Upgrade the AKS instance with agent pool profiles (idempontent)
  azure_rm_aks:
    name: "aks{{ rpfx }}"
    resource_group: "{{ resource_group }}"
    location: eastus
    dns_prefix: "aks{{ rpfx }}"
    kubernetes_version: "{{ version1.azure_aks_versions[0] }}"
    service_principal:
      client_id: "{{ azure_client_id }}"
      client_secret: "{{ azure_secret }}"
    linux_profile:
      admin_username: azureuser
      ssh_key: ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDSPmiqkvDH1/+MDAVDZT8381aYqp73Odz8cnD5hegNhqtXajqtiH0umVg7HybX3wt1HjcrwKJovZURcIbbcDvzdH2bnYbF93T4OLXA0bIfuIp6M86x1iutFtXdpN3TTicINrmSXEE2Ydm51iMu77B08ZERjVaToya2F7vC+egfoPvibf7OLxE336a5tPCywavvNihQjL8sjgpDT5AAScjb3YqK/6VLeQ18Ggt8/ufINsYkb+9/Ji/3OcGFeflnDXq80vPUyF3u4iIylob6RSZenC38cXmQB05tRNxS1B6BXCjMRdy0v4pa7oKM2GA4ADKpNrr0RI9ed+peRFwmsclH test@ansible
    agent_pool_profiles:
      - name: default
        count: 1
        vm_size: Standard_B2s
        type: VirtualMachineScaleSets
        mode: System
        enable_auto_scaling: true
        max_count: 6
        min_count: 1
        max_pods: 42
        availability_zones:
          - 1
          - 2
    node_resource_group: "node{{ noderpfx }}"
    enable_rbac: true
    network_profile:
      load_balancer_sku: standard
  register: output

- name: Assert the AKS instance is well created
  ansible.builtin.assert:
    that:
      - not output.changed

- name: Upgrade the AKS instance with multiple agent pool profiles
  azure_rm_aks:
    name: "aks{{ rpfx }}"
    resource_group: "{{ resource_group }}"
    location: eastus
    dns_prefix: "aks{{ rpfx }}"
    kubernetes_version: "{{ version1.azure_aks_versions[0] }}"
    service_principal:
      client_id: "{{ azure_client_id }}"
      client_secret: "{{ azure_secret }}"
    linux_profile:
      admin_username: azureuser
      ssh_key: ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDSPmiqkvDH1/+MDAVDZT8381aYqp73Odz8cnD5hegNhqtXajqtiH0umVg7HybX3wt1HjcrwKJovZURcIbbcDvzdH2bnYbF93T4OLXA0bIfuIp6M86x1iutFtXdpN3TTicINrmSXEE2Ydm51iMu77B08ZERjVaToya2F7vC+egfoPvibf7OLxE336a5tPCywavvNihQjL8sjgpDT5AAScjb3YqK/6VLeQ18Ggt8/ufINsYkb+9/Ji/3OcGFeflnDXq80vPUyF3u4iIylob6RSZenC38cXmQB05tRNxS1B6BXCjMRdy0v4pa7oKM2GA4ADKpNrr0RI9ed+peRFwmsclH test@ansible
    agent_pool_profiles:
      - name: default
        count: 1
        vm_size: Standard_B2s
        type: VirtualMachineScaleSets
        mode: System
        enable_auto_scaling: true
        max_count: 6
        min_count: 1
        max_pods: 42
        availability_zones:
          - 1
          - 2
      - name: default2
        count: 1
        vm_size: Standard_B2s
        type: VirtualMachineScaleSets
        mode: User
    node_resource_group: "node{{ noderpfx }}"
    enable_rbac: true
    network_profile:
      load_balancer_sku: standard
  register: output
  ignore_errors: true

- name: Assert the AKS instance is well created
  ansible.builtin.assert:
    that:
      - output.changed
      - "output.agent_pool_profiles | length == 2"
      - output.provisioning_state == 'Succeeded'
      - output.agent_pool_profiles[1].mode == 'User'
  ignore_errors: true
  register: ignore_errors_register

- name: Upgrade the AKS instance with multiple agent pool profiles (idempontent)
  azure_rm_aks:
    name: "aks{{ rpfx }}"
    resource_group: "{{ resource_group }}"
    location: eastus
    dns_prefix: "aks{{ rpfx }}"
    kubernetes_version: "{{ version1.azure_aks_versions[0] }}"
    service_principal:
      client_id: "{{ azure_client_id }}"
      client_secret: "{{ azure_secret }}"
    linux_profile:
      admin_username: azureuser
      ssh_key: ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDSPmiqkvDH1/+MDAVDZT8381aYqp73Odz8cnD5hegNhqtXajqtiH0umVg7HybX3wt1HjcrwKJovZURcIbbcDvzdH2bnYbF93T4OLXA0bIfuIp6M86x1iutFtXdpN3TTicINrmSXEE2Ydm51iMu77B08ZERjVaToya2F7vC+egfoPvibf7OLxE336a5tPCywavvNihQjL8sjgpDT5AAScjb3YqK/6VLeQ18Ggt8/ufINsYkb+9/Ji/3OcGFeflnDXq80vPUyF3u4iIylob6RSZenC38cXmQB05tRNxS1B6BXCjMRdy0v4pa7oKM2GA4ADKpNrr0RI9ed+peRFwmsclH test@ansible
    agent_pool_profiles:
      - name: default
        count: 1
        vm_size: Standard_B2s
        type: VirtualMachineScaleSets
        enable_auto_scaling: true
        max_count: 6
        min_count: 1
        max_pods: 42
        availability_zones:
          - 1
          - 2
      - name: default2
        count: 1
        vm_size: Standard_B2s
        type: VirtualMachineScaleSets
        mode: User
    node_resource_group: "node{{ noderpfx }}"
    enable_rbac: true
    network_profile:
      load_balancer_sku: standard
  register: output

- name: Assert the AKS instance is well created
  ansible.builtin.assert:
    that:
      - not output.changed

- name: Update the default2 agent_pool mode from User to System
  azure_rm_aks:
    name: "aks{{ rpfx }}"
    resource_group: "{{ resource_group }}"
    location: eastus
    dns_prefix: "aks{{ rpfx }}"
    kubernetes_version: "{{ version1.azure_aks_versions[0] }}"
    service_principal:
      client_id: "{{ azure_client_id }}"
      client_secret: "{{ azure_secret }}"
    linux_profile:
      admin_username: azureuser
      ssh_key: ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDSPmiqkvDH1/+MDAVDZT8381aYqp73Odz8cnD5hegNhqtXajqtiH0umVg7HybX3wt1HjcrwKJovZURcIbbcDvzdH2bnYbF93T4OLXA0bIfuIp6M86x1iutFtXdpN3TTicINrmSXEE2Ydm51iMu77B08ZERjVaToya2F7vC+egfoPvibf7OLxE336a5tPCywavvNihQjL8sjgpDT5AAScjb3YqK/6VLeQ18Ggt8/ufINsYkb+9/Ji/3OcGFeflnDXq80vPUyF3u4iIylob6RSZenC38cXmQB05tRNxS1B6BXCjMRdy0v4pa7oKM2GA4ADKpNrr0RI9ed+peRFwmsclH test@ansible
    agent_pool_profiles:
      - name: default
        count: 1
        vm_size: Standard_B2s
        type: VirtualMachineScaleSets
        mode: System
        enable_auto_scaling: true
        max_count: 6
        min_count: 1
        max_pods: 42
        availability_zones:
          - 1
          - 2
      - name: default2
        count: 1
        vm_size: Standard_B2s
        type: VirtualMachineScaleSets
        mode: System
    node_resource_group: "node{{ noderpfx }}"
    enable_rbac: true
    network_profile:
      load_balancer_sku: standard
  ignore_errors: true
  register: output

- name: Assert the AKS instance is well created
  ansible.builtin.assert:
    that:
      - output.changed
      - "output.agent_pool_profiles | length == 2"
      - output.provisioning_state == 'Succeeded'
      - output.agent_pool_profiles[1].mode == 'System'
  ignore_errors: true
  register: ignore_errors_register

- name: Update the default2 agent_pool mode from User to System (idempontent)
  azure_rm_aks:
    name: "aks{{ rpfx }}"
    resource_group: "{{ resource_group }}"
    location: eastus
    dns_prefix: "aks{{ rpfx }}"
    kubernetes_version: "{{ version1.azure_aks_versions[0] }}"
    service_principal:
      client_id: "{{ azure_client_id }}"
      client_secret: "{{ azure_secret }}"
    linux_profile:
      admin_username: azureuser
      ssh_key: ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDSPmiqkvDH1/+MDAVDZT8381aYqp73Odz8cnD5hegNhqtXajqtiH0umVg7HybX3wt1HjcrwKJovZURcIbbcDvzdH2bnYbF93T4OLXA0bIfuIp6M86x1iutFtXdpN3TTicINrmSXEE2Ydm51iMu77B08ZERjVaToya2F7vC+egfoPvibf7OLxE336a5tPCywavvNihQjL8sjgpDT5AAScjb3YqK/6VLeQ18Ggt8/ufINsYkb+9/Ji/3OcGFeflnDXq80vPUyF3u4iIylob6RSZenC38cXmQB05tRNxS1B6BXCjMRdy0v4pa7oKM2GA4ADKpNrr0RI9ed+peRFwmsclH test@ansible
    agent_pool_profiles:
      - name: default
        count: 1
        vm_size: Standard_B2s
        type: VirtualMachineScaleSets
        enable_auto_scaling: true
        max_count: 6
        min_count: 1
        max_pods: 42
        availability_zones:
          - 1
          - 2
      - name: default2
        count: 1
        vm_size: Standard_B2s
        type: VirtualMachineScaleSets
        mode: System
    node_resource_group: "node{{ noderpfx }}"
    enable_rbac: true
    network_profile:
      load_balancer_sku: standard
  register: output

- name: Get AKS fact
  azure_rm_aks_info:
    name: "aks{{ rpfx }}"
    resource_group: "{{ resource_group }}"
    show_kubeconfig: user
  register: fact

- name: Assert fact returns the created one
  ansible.builtin.assert:
    that:
      - "fact.aks | length == 1"
      - fact.aks[0].kube_config == output.kube_config

- name: Delete the AKS instance
  azure_rm_aks:
    name: "aks{{ rpfx }}"
    resource_group: "{{ resource_group }}"
    state: absent
  register: output

- name: Assert the AKS instance is well deleted
  ansible.builtin.assert:
    that:
      - output.changed

- name: Delete the AKS instance (idempotent)
  azure_rm_aks:
    name: "aks{{ rpfx }}"
    resource_group: "{{ resource_group }}"
    state: absent
  register: output

- name: Assert idempotent
  ansible.builtin.assert:
    that:
      - not output.changed

- name: Get AKS fact
  azure_rm_aks_info:
    name: "aks{{ rpfx }}"
    resource_group: "{{ resource_group }}"
  register: fact

- name: Assert fact returns empty
  ansible.builtin.assert:
    that:
      - "fact.aks | length == 0"
